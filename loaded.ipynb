{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "",
  "signature": "sha256:89eaa6d91ecc848d7a21cc9b2765789f66554b051c14d22de2dafab80820668b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from tensorflow.python.ops import rnn, rnn_cell\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "from util import minibatcher, RNN"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Indicate all of the training constants"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classes = [\"walking\", \"sitting\", \"table\", \"stairs\", \"car\"]\n",
      "\n",
      "n_hidden = 100 # Size of the LSTM hidden layer\n",
      "batch_size = 8 # Number of data points in a batch\n",
      "learning_rate = 0.01 # Learning rate of the optimizer\n",
      "dropout_keep_prob = .8\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Import the data, and split it into training and testing sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_data = np.load(\"gmail/clean_data.npy\")\n",
      "data_labels = np.load(\"gmail/labels.npy\")\n",
      "\n",
      "# Update the dataset to only be the labeled data (the ones that aren't 0)\n",
      "labeled = data_labels != 0\n",
      "input_motion_data = clean_data[labeled]\n",
      "output_motion_data = data_labels[labeled] - 1 # Need to decrement by 1 since we removed all the 0s\n",
      "n_samples = input_motion_data.shape[0]\n",
      "n_steps = input_motion_data.shape[1]\n",
      "n_input = input_motion_data.shape[2]\n",
      "n_classes = np.max(output_motion_data) + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = np.load(\"X_train.npy\")\n",
      "Y_train = np.load(\"Y_train.npy\")\n",
      "X_test = np.load(\"X_test.npy\")\n",
      "Y_test = np.load(\"Y_test.npy\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip(classes, np.bincount(np.argmax(Y_train, axis=1)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "[('walking', 48), ('sitting', 48), ('table', 48), ('stairs', 48), ('car', 48)]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Define the placeholders and variables to be optimized"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
      "y = tf.placeholder(\"float\", [None, n_classes])\n",
      "keep_prob = tf.placeholder(tf.float32)\n",
      "# Define weights\n",
      "weights = {\n",
      "    'hidden': tf.Variable(tf.random_normal([n_hidden, n_hidden])),\n",
      "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
      "}\n",
      "biases = {\n",
      "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
      "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Define the various graphs: notably cost, optimizer, and accuracy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = RNN(x, weights, biases, n_input, n_steps, n_hidden, keep_prob)\n",
      "\n",
      "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
      "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
      "\n",
      "# Evaluate model\n",
      "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
      "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load the trained model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add ops to save and restore all the variables.\n",
      "saver = tf.train.Saver()\n",
      "\n",
      "# Later, launch the model, use the saver to restore variables from disk, and\n",
      "# do some work with the model.\n",
      "sess = tf.Session()\n",
      "# Restore variables from disk.\n",
      "saver.restore(sess, \"trained_model.ckpt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sess.run(accuracy, feed_dict={x: X_test, y: Y_test, keep_prob: 1.0})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "0.66666669"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argmax(sess.run(pred, feed_dict={x: X_test, y: Y_test, keep_prob: 1.0}), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array([0, 3, 2, 2, 2, 1, 1, 3, 0, 2, 2, 0, 2, 2, 1, 2, 1, 3, 2, 4, 3, 0, 0,\n",
        "       3, 2, 0, 1, 0, 4, 1, 4, 2, 1, 4, 1, 3, 1, 3, 1, 2, 0, 0, 4, 2, 3, 4,\n",
        "       3, 3, 1, 1, 4, 0, 1, 0, 1, 1, 4, 0, 2, 2, 0, 1, 1, 2, 3, 3, 3, 0, 1,\n",
        "       4, 0, 0, 1, 1, 0])"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argmax(Y_test, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([4, 0, 2, 2, 2, 1, 1, 3, 0, 2, 2, 3, 2, 2, 1, 2, 4, 3, 2, 4, 4, 0, 0,\n",
        "       3, 2, 0, 1, 0, 4, 0, 3, 2, 4, 4, 4, 0, 1, 0, 1, 2, 3, 0, 4, 2, 3, 4,\n",
        "       4, 3, 4, 4, 4, 4, 1, 0, 4, 1, 4, 0, 2, 2, 3, 4, 1, 2, 4, 0, 3, 3, 1,\n",
        "       4, 3, 0, 1, 4, 3])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Count which classes were confused "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get indices of incorrect predictions in the test set\n",
      "test_predicted = np.argmax(sess.run(pred, feed_dict={x: X_test, keep_prob: 1.0}), axis=1)\n",
      "test_actual = np.argmax(Y_test, axis=1)\n",
      "wrong_predictions = test_predicted != test_actual\n",
      "\n",
      "mistakes = zip(test_predicted[wrong_predictions], test_actual[wrong_predictions])\n",
      "# Sort the predicted/expected so that mistaking class 1 for class 3 is the same \n",
      "# as mistaking class 3 for class 1, for example\n",
      "mistakes = sorted(map(lambda x: sorted(x), mistakes))\n",
      "# Convert classs number to class names\n",
      "mistakes = map(lambda p: (classes[p[0]], classes[p[1]]), mistakes)\n",
      "\n",
      "from collections import Counter\n",
      "for m, n in Counter(mistakes).most_common():\n",
      "    print \"%s: %d\" % (str(m), n)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('walking', 'stairs'): 10\n",
        "('sitting', 'car'): 8\n",
        "('stairs', 'car'): 4\n",
        "('walking', 'car'): 2\n",
        "('walking', 'sitting'): 1\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Classify the Unlabelled data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unlabeled = data_labels == 0\n",
      "input_motion_data = clean_data[unlabeled]\n",
      "\n",
      "Y = np.argmax(sess.run(pred, feed_dict={x: input_motion_data, keep_prob: 1.0}), axis=1)\n",
      "class_count = zip(classes, np.bincount(Y))\n",
      "\n",
      "for c in class_count:\n",
      "    print \"%s: %d\" % (c[0], c[1])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "walking: 10\n",
        "sitting: 116\n",
        "table: 20\n",
        "stairs: 38\n",
        "car: 29\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}
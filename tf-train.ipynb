{
 "metadata": {
  "name": "",
  "signature": "sha256:4af8824d333ed03bbaf60594520a051a8379c3522a38b964ed3f3542fdc9ee3b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from tensorflow.python.ops import rnn, rnn_cell\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Set up the minibatcher for batch learning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def minibatcher(data_x, data_y, batch_size, num_repeats):\n",
      "    assert(data_x.shape[0])\n",
      "    data_size = data_x.shape[0]\n",
      "    for _ in range(num_repeats):\n",
      "        start = 0\n",
      "        while start < data_size:\n",
      "            yield data_x[start:start + batch_size], data_y[start:start + batch_size]\n",
      "            start += batch_size\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Indicate all of the training constants"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_hidden = 100 # Size of the LSTM hidden layer\n",
      "batch_size = 8 # Number of data points in a batch\n",
      "learning_rate = 0.001 # Learning rate of the optimizer\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Import the data, and split it into training and testing sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input_motion_data = np.load(\"gmail/clean_data.npy\")\n",
      "output_motion_data = np.load(\"gmail/labels.npy\")\n",
      "n_samples = input_motion_data.shape[0]\n",
      "n_steps = input_motion_data.shape[1]\n",
      "n_input = input_motion_data.shape[2]\n",
      "n_classes = np.max(output_motion_data) + 1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_classes = np.zeros((n_samples, n_classes))\n",
      "for i in range(n_samples):\n",
      "    output_classes[i, output_motion_data[i]] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, Y_train, Y_test = train_test_split(input_motion_data, output_classes, test_size=.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Define the placeholders and variables to be optimized"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
      "y = tf.placeholder(\"float\", [None, n_classes])\n",
      "# Define weights\n",
      "weights = {\n",
      "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
      "}\n",
      "biases = {\n",
      "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Define the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def RNN(x, weights, biases):\n",
      "\n",
      "    # Prepare data shape to match `rnn` function requirements\n",
      "    # Current data input shape: (batch_size, n_steps, n_input)\n",
      "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
      "    \n",
      "    # Permuting batch_size and n_steps\n",
      "    x = tf.transpose(x, [1, 0, 2])\n",
      "    # Reshaping to (n_steps*batch_size, n_input)\n",
      "    x = tf.reshape(x, [-1, n_input])\n",
      "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
      "    x = tf.split(0, n_steps, x)\n",
      "\n",
      "    # Define a lstm cell with tensorflow\n",
      "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
      "\n",
      "    # Get lstm cell output\n",
      "    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n",
      "\n",
      "    # Linear activation, using rnn inner loop last output\n",
      "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Define the various graphs: notably cost, optimizer, and accuracy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = RNN(x, weights, biases)\n",
      "\n",
      "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
      "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
      "\n",
      "# Evaluate model\n",
      "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
      "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Run the optimization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sess = tf.Session()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sess.run(tf.initialize_all_variables())\n",
      "\n",
      "for (rep, (batch_x, batch_y)) in enumerate(minibatcher(X_train,Y_train,10, 20)):\n",
      "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
      "    if rep % 5 == 0:\n",
      "        # Calculate batch accuracy\n",
      "        acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
      "        test_acc = sess.run(accuracy, feed_dict={x: X_test, y: Y_test})\n",
      "        # Calculate batch loss\n",
      "        loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
      "        print \"Batch \" + str(rep) + \", Minibatch Loss= \" + \\\n",
      "              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
      "              \"{:.5f}\".format(acc) + \", Test Accuracy= \" + \"{:.5f}\".format(test_acc)\n",
      "final_test_acc = sess.run(accuracy, feed_dict={x: X_test, y: Y_test})\n",
      "print \"Final Test accuracy = \" + \"{:.5f}\".format(final_test_acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}